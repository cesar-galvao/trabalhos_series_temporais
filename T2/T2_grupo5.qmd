---
title: "Trabalho Prático 2"
subtitle: "Análise de Séries Temporais - 1/2023" 
author:
  - Ana Carolina Vianna - 18/0097261
  - César Augusto Galvão - 19/0011572
  - Yan Flávio Vianna - 14/0166149
format: 
  pdf:
    toc: true
    toc-depth: 2
    keep-tex: true
    include-in-header:
      text: |
        \usepackage[auth-lg]{authblk}
execute:
  echo: false
  message: false
  warning: false
---

{{< pagebreak >}}

# Introdução: série selecionada, características e decomposição

```{r pacotes}
if(!("pacman" %in% installed.packages())){install.packages("pacman")}

pacman::p_load(Mcomp, tidyverse, forecast, fpp2, xts, tseries, tidymodels, kableExtra)

# #funcao not in para facilitar filtragens
# `%notin%` <- Negate(`%in%`)
```

```{r selecao-dados}
# T2 -> 2169 ou 2183

data(M3) #carrega os dados
id <- 2183 #série temporal escolhida

serie <- M3[[id]]

dados <- serie$x
```

A série temporal escolhida foi a de número *id* correspondente a `r id`. De acordo com a definição do próprio pacote, refere-se a *`r serie$description`*. Foram realizadas medidas mensais de 1983 a 1992 e o horizonte de previsão requerido é das 18 ocorrências seguintes.

O gráfico da série, com *in* e *out-sample*, é exposto a seguir.

```{r plot-serie-total}

plot(serie, main = "Série Temporal M3-2183")

```

A série aparenta ter dois períodos, pelo menos: um ciclo anual e outro que compreende um período maior. No entanto, ao se tentar decompor a série com múltiplas sazonalidades, obté-se o seguinte:

-   **Adicionando uma componente sazonal com ciclo menor que 1 ano** -- uma das componentes sazonais apresenta heteroscedasticidade;
-   **Adicionando uma componente sazonal com ciclo maior que 1 ano** -- resíduos apresentam periodicidade ou heteroscedasticidade.

```{r decomposicao-mstl}
serie_ms <- forecast::msts(dados, seasonal.periods = c(12))

# media dos resíduos é em torno de 5. Considerando a magnitude dos dados que temos usando summary(dados), está próximo de zero o suficiente

#tentei períodos secundários, porém o melhor ajuste é com apenas um ciclo anual. Só é possível dois ciclos secundários completos para análise até quadrienal, mas até aí todos apresentam resíduos inadequados. 

decomp_mstl <- mstl(serie_ms, lambda = NULL, t.window = 9)

#ajustar com lambda = "auto" até agora não parece fazer qualquer diferença

```

Optou-se portanto pela decomposição STL (apesar de os dados terem inicialmente formado um objeto `msts`) apenas com a sazonalidade anual, mas fica evidente que esta decomposição não é adequada quando se avalia a componente de tendência, que aparenta ainda carregar algum componente periódico. Os resíduos aparentam um comportamento aleatório e têm média `r round(mean(decomp_mstl[,4]),3)`, o que é próximo de zero o suficiente considerando a magnitude dos dados da série. A decomposição é exposta a seguir.

```{r grafico-mstl}

decomp_mstl %>% autoplot(main = "Decomposição MSTL com período anual simples") + labs(x = "Ano") + theme_bw()

```

# Modelos ARIMA: seleção, transformações e resíduos

## Modelo sem transformação

### Seleção

Primeiramente, utilizou-se as funções *ndiffs()* e *nsdiffs()* do pacote *forecast* para identificar quantas diferenças simples e sazonais seriam necessárias para que a série se tornasse estacionária. Concluiu-se pelo resultado dessas funções que são necessárias uma diferenciação simples e uma sazonal. O teste KPSS confirma isso ao não rejeitar a hipótese nula de estacionariedade da série (com diferenças já aplicadas) ao nível de 5% de significância.[^1]

[^1]: Para todos os demais testes de hipótese, toma-se como referência $\alpha = 0,05$ o nível de significância para regra de decisão.

```{r diff-arima}
# diferenciacoes comuns
# ndiffs(serie_ms)

#diferenciacoes sazonais
# serie_ms %>% diff() %>% nsdiffs()

serie_ms_diff <- serie_ms %>% diff() %>% diff(lag = 12)

# Inicializacao dos resíduos
fit <- Arima(dados, order=c(2,1,2), seasonal=c(0,1,2)) #modelo selecionado em outro estágio da análise
E <- window(fit$residuals, start=c(1984,1))

kpss.test(E) %>% 
  tidy()%>%
  select(method, statistic, `p.value`) %>%
  knitr::kable(
    format = "latex",
    align = c("lccc"),
    booktabs = TRUE,
    longtable = TRUE,
    linesep = "",
    escape = FALSE,
    digits = 2,
    col.names = c("", "Estatística", "p-valor")
    ) %>%
  kableExtra::kable_styling(
      position = "center",
      latex_options = c("striped", "repeat_header"),
      stripe_color = "gray!15")
```

Prosseguimos com a seleção do melhor modelo ARIMA avaliando os gráficos de ACF e PACF. O primeiro parece apresentar quebra no primeiro lag sazonal, enquanto o segundo tem quebra no segundo lag simples, configurando um $\text{ARIMA}(2,1,0)\times(0,1,1)_{12}$ (porém os resíduos para este modelo não ficam muito bons). Entretanto, como não fica nítido um comportamento de queda amortizada, preferiu-se utilizar outro critério para a seleção do modelo.

```{r acf-pacf-sem-transformacao, fig.height=3, fig.width = 8}
# Graficos de Autocorrelacao
par(mfrow=c(1,3))
plot(serie_ms_diff, main="Série com diferenças",ylab="")
acf(serie_ms_diff, lag=12*6, main="ACF")
pacf(serie_ms_diff, lag=12*6, main="PACF")
```

Optou-se pela varredura de combinações de $p$, $q$, $P$ e $Q$, com $d$ e $D$ fixados em 1, como resultado das diferenciações ja avaliadas. Utilizando o critério de Akaike corrigido, seleciona-se o modelo $\text{ARIMA}(2,1,2)\times(0,1,2)_{12}$ para a série, que possui o menor escore entre os modelos testados.

Ao se utilizar a função `auto.arima()`, recebe-se um modelo sugerido $\text{ARIMA}(2,1,2)\times(2,1,0)_{12}$, porém com AICc superior àquele identificado na varredura. Opta-se pelo modelo selecionado manualmente.

```{r aicc-sem-transformacao, include = FALSE}
melhor_AICc <- Inf
for(p in 0:2){
  for(q in 0:2){
    for(P in 0:2){
      for(Q in 0:2){
        
        #cat("p =",p,", q =",q,", P =",P,", Q =",Q,"\n")
        
        tryCatch({fit <- Arima(serie_ms, order=c(p,1,q), seasonal=c(P,1,Q))}, error=function(e){cat("",conditionMessage(e), "\n")})
        
        if(fit$aicc <= melhor_AICc){
          melhor_AICc <- fit$aicc
          #cat("p =",p,", q =",q,", P =",P,", Q =",Q,", AICc =",fit$aicc,"\n")
          }
        
      }
    }
  }
}

#melhor_AICc

# teste com auto.arima para verificar
#auto.arima(serie_ms)
```

### Resíduos

Foram retirados os zeros da inicialização para possibilitar a análise dos resíduos. Observa-se pelo gráfico que os resíduos são aleatórios e aparentemente centrados em zero, com variação constante. Além disso, verifica-se uma distribuição aproximadamente normal, mas com caudas mais pesadas. Finalmente, o gráfico ACF apresenta que a autocorrelação dos resíduos está, em sua grande maioria, dentro da banda de confiança, com exceção de um ponto, que extrapola ligeiramente a margem.

```{r residuos-arima, fig.height=3, fig.width = 8}

# Analise de residuos
par(mfrow=c(1,3))
plot(E, main="Resíduos",ylab="")
qqnorm(E)
qqline(E)
acf(E,lag.max=12*6,main="ACF")
```

Por fim, realiza-se testes de hipótese para independência e normalidade (o teste KPSS para estacionariedade já foi apresentado) e seus resultados são apresentados na tabela a seguir. De fato, o teste de Shapiro-Wilk não rejeita a normalidade da distribuição dos resíduos apesar de o gráfico QQ apresentar caudas pesadas. Além disso, o teste Ljung-Box com *lag* igual a 15 também não rejeita a independência entre os resíduos e, consequentemente, os dados da série.

```{r testes-arima}
#Testes
box <- Box.test(E,lag=15,type="Ljung-Box") %>% tidy() %>% select(method, everything()) %>% mutate(parameter = as.character(parameter)) #independencia
shap <- shapiro.test(E) %>% tidy() %>% mutate(parameter = "") %>% select(method, everything())  #normalidade

bind_rows(box, shap) %>%
  knitr::kable(
    format = "latex",
    align = c("lccc"),
    booktabs = TRUE,
    longtable = TRUE,
    linesep = "",
    escape = FALSE,
    digits = 2,
    col.names = c("", "Estatística", "p-valor", "Lag")
    ) %>%
  kableExtra::kable_styling(
      position = "center",
      latex_options = c("striped", "repeat_header"),
      stripe_color = "gray!15")

rm(box, shap)
```

## Modelo com transformação

### Seleção

```{r transformacao-boxcox}
# Transformacao de Box-Cox
autolambda <- BoxCox.lambda(dados)
dadosbc <- BoxCox(dados, lambda=autolambda)

```

Foi utilizada a função *BoxCox.lambda()* do pacote *forecast* para decidir de forma automatizada o melhor valor de lambda para a transformação de Box-Cox. A função sugere um valor de $\lambda =$ `r round(autolambda,2)`.

Apesar de haver uma sugestão de transformação, não é possível avaliar graficamente se houve uma diferença significativa no comportamento da série temporal excetuando-se a escala, como se pode ver nos eixos dos gráficos a seguir.

```{r comparacao-transformacao-arima, fig.height=4.5, fig.width = 8}
par(mfrow=c(1,2))
plot(dados, main='Série original',ylab='')
plot(dadosbc, main='Série transformada',ylab='')
```

Após aplicar a tranformação de Box-Cox na série, utilizou-se as funções *ndiffs()* e *nsdiffs()* para identificar quantas diferenciações simples e sazonais seriam necessárias para que a série se torne estacionária. Concluiu-se que são necessárias uma diferenciações simples e uma diferenciações sazonal, o que é confirmado pelo resultado do teste KPSS nos resíduos da série com as diferenças já aplicadas.

```{r diff-arima-boxcox}
# Diferencas (BC)
# ndiffs(dadosbc)
# dadosbc %>% diff() %>% nsdiffs()

dadosbcdiff <- dadosbc %>% diff() %>% diff(lag = 12)

fit2 <- Arima(dadosbc, order=c(2,1,2), seasonal=c(0,1,2))# modelo ajustado em etapa posterior da análise

E2 <- window(fit2$residuals, start=c(1984,1))

kpss.test(E2) %>% 
  tidy()%>%
  select(method, statistic, `p.value`) %>%
  knitr::kable(
    format = "latex",
    align = c("lccc"),
    booktabs = TRUE,
    longtable = TRUE,
    linesep = "",
    escape = FALSE,
    digits = 2,
    col.names = c("", "Estatística", "p-valor")
    ) %>%
  kableExtra::kable_styling(
      position = "center",
      latex_options = c("striped", "repeat_header"),
      stripe_color = "gray!15")
```

O gráfico da ACF parece apresentar quebra no primeiro lag sazonal, enquanto o PACF tem quebra no segundo lag simples, o que configura um $\text{ARIMA}(2,1,0)\times(0,1,1)_{12}$ (porém, mais uma vez, os resíduos para este modelo não ficam muito bons). Entretanto, os gráficos não evidenciam comportamentos claros para a série. Novamente, os resíduos parecem ter média igual a zero.

```{r acf-pacf-arima-boxcox, fig.height=3, fig.width = 8}
# Graficos de Autocorrelacao (BC)
par(mfrow=c(1,3))
plot(dadosbcdiff, main="Série (boxcox) com dif.",ylab="")
acf(dadosbcdiff, lag=12*6, main="ACF")
pacf(dadosbcdiff, lag=12*6, main="PACF")
```

Foram testadas combinações de $p$, $q$, $P$ e $Q$, com $d$ e $D$ fixados em 1 e, em seguida, selecionou-se o modelo ARIMA que apresentava menor valor do AICc. Temos, então, que o modelo escolhido para a série transformada é um $\text{ARIMA}(2,1,2)\times(0,1,2)_{12}$, assim como no caso da série sem transformação. Utilizando-se a função `auto.arima()` recebe-se uma sugestão de um modelo $ARIMA(3,1,1)\times(2,1,0)_{12}$ mas, assim como ocorre no modelo sem transformação, opta-se pelo modelo selecionado manualmente por apresentar um AICc menor.

```{r aicc-arima-boxcox, include = FALSE}
# Criterio de Akaike (BC)
melhor_AICc <- Inf
for(p in 0:2){
  for(q in 0:2){
    for(P in 0:2){
      for(Q in 0:2){
        #cat("p =",p,", q =",q,", P =",P,", Q =",Q,"\n")
        tryCatch({fit <- Arima(dadosbc, order=c(p,1,q), seasonal=c(P,1,Q))}, error=function(e){cat("ERROR :",conditionMessage(e), "\n")})
        if(fit$aicc <= melhor_AICc){
          melhor_AICc <- fit$aicc
          #cat("p =",p,", q =",q,", P =",P,", Q =",Q,", AICc =",fit$aicc,"\n")}
        
      }
    }
  }
  }
}
# melhor_AICc

# auto.arima(serie_ms)

```

### Resíduos

Foram retirados os zeros da inicialização para seguir com a análise dos resíduos. O gráfico da série dos resíduos sugere aleatoriedade e o QQ plot distribuição aproximadamente normal. Por último, o gráfico ACF mostra que a autocorrelação dos resíduos está dentro da banda de confiança, com exceção de um ponto que excede um pouco este limite.

```{r residuos-arima-boxcox, fig.height=3, fig.width = 8}
# Inicializacao
# Analise de residuos
par(mfrow=c(1,3))
plot(E2, main="Resíduos (boxcox)",ylab="")
qqnorm(E2)
qqline(E2)
acf(E,lag.max=12*6,main="ACF")
```

Assim como ocorre para a série não transformada, os testes de Shapiro-Wilk e Ljung-box com *lag* igual a 15 não apresentam indicação para rejeição de suas hipóteses nulas. Isto é, pode-se dizer que a série transformada tem distribuição normal e seus resíduos são independentes.

```{r testes-arima-boxcox}
#Testes
box <- Box.test(E2,lag=15,type="Ljung-Box") %>% tidy() %>% select(method, everything()) %>% mutate(parameter = as.character(parameter)) #independencia
shap <- shapiro.test(E2) %>% tidy() %>% mutate(parameter = "") %>% select(method, everything())  #normalidade

bind_rows(box, shap) %>%
  knitr::kable(
    format = "latex",
    align = c("lccc"),
    booktabs = TRUE,
    longtable = TRUE,
    linesep = "",
    escape = FALSE,
    digits = 2,
    col.names = c("", "Estatística", "p-valor", "Lag")
    ) %>%
  kableExtra::kable_styling(
      position = "center",
      latex_options = c("striped", "repeat_header"),
      stripe_color = "gray!15")

rm(box, shap)
```

# Modelos ETS: seleção, transformações e resíduos

## Modelo sem transformação

### Seleção

Para a seleção do modelo ETS, foi realizada uma varredura com todas as combinações possíveis de erro, tendência e sazonalidade, assim como a aplicação ou não de *damp* na tendência. Os seis modelos com melhores indicadores são exibidos na tabela a seguir para comparação.

```{r selecao-ETS-sem-transf}
# monta as combinações possíveis de modelo ets
model <- expand_grid(v1 = c("A", "M", "N"), v2 = c("A", "M", "N"), v3 = c("A", "M", "N")) %>%
  mutate(modelo = str_c(v1,v2,v3)) %>%
  select(modelo) %>%
  unique() %>%
  expand_grid(., damp = c(TRUE, FALSE))
# N, A, M, + damped


#funcao pra montar indicadores do modelo
criterios <- function(modelo, damp, dados) { 
  ETS <- ets(dados, model = modelo, damped = damp)
  #usamos o objeto dados como um padrao
  
  tabela <- tibble(
    nome = modelo,
    sigla = str_c("ETS(", str_c(substr(modelo,1,1),  substr(modelo,2,2), substr(modelo,3,3), sep = ","), ")"),
    damped = damp,
    AIC = ETS$aic, 
    AICc = ETS$aicc, 
    BIC = ETS$bic)
  
  return(tabela)
}


#selecionando modelos permitidos pela funcao ets
# for(i in 1:length(model$modelo)){
#   print(i)
#   print(try({ets(dados, model = model$modelo[i], damped = model$damp[i])}, silent = TRUE))
# }

selecionados <- c(1, 2, 5, 6, 14, 18:24, 27:30, 32, 34, 36)

model_select <- model[selecionados,]

tabela_modelos_ETS <- map2_df(model_select$modelo, model_select$damp, criterios, dados) %>%
  arrange(AIC) %>%
  mutate(modelo = case_when(
    damped == TRUE ~ str_replace(sigla, ",A", ",Ad"),
    .default = sigla
  ))

tabela_modelos_ETS %>%
  select("Modelo"= modelo, AIC:BIC)%>%
  head(6) %>%
  knitr::kable(
    format = "latex",
    align = c("lccc"),
    booktabs = TRUE,
    longtable = TRUE,
    linesep = "",
    escape = FALSE,
    digits = 2
    ) %>%
  kableExtra::kable_styling(
      position = "center",
      latex_options = c("striped", "repeat_header"),
      stripe_color = "gray!15")

```

De fato, modelos que misturam termos aditivos e multiplicativos apresentam os melhores indicadores AICc, mas o desempenho da função `ets()` é instável nessas condições. Por isso, opta-se pelo uso do terceiro melhor modelo, $ETS(A, Ad, A)$. A decomposição da série temporal analisada utilizando este modelo é exposta no gráfico a seguir.

```{r melhor-fit-ETL-sem-transf}

# decomposicao ETS sem transformacao ----
fit_ets <- ets(dados, model = "AAA", damped = TRUE)

plot(fit_ets)

```

### Resíduos

Uma análise visual dos resíduos indica comportamento aleatório em torno de zero e autocorrelações próximas a zero. Quanto à distribuição, a amostra parece ter uma distribuição próxima à normal, mas com caudas mais pesadas.

```{r residuos-ets-sem-transform, fig.height=5, fig.width = 7, fig.align='center'}

# Análise de resíduos ETS sem transformação
E3 <- fit_ets$residuals
par(mfrow=c(2,2))
plot(E3, main = "Resíduos")
acf(E3)
pacf(E3)
qqnorm(E3)
qqline(E3)

```

Observa-se ainda pelo resultado dos testes de hipótese a seguir temos uma série estacionária, com resíduos normalmente distribuídos e mutuamente independentes.

```{r residuos-ets-sem-transformacao}
# # Testes para ETS sem transformação
box <- Box.test(E3,lag=15,type="Ljung-Box") %>% tidy() %>% select(method, everything()) %>% mutate(parameter = as.character(parameter)) #independencia
shap <- shapiro.test(E3) %>% tidy() %>% mutate(parameter = "") %>% select(method, everything())  #normalidade
kpss <- kpss.test(E3) %>% tidy() %>% select(method, everything()) %>% mutate(parameter = as.character(parameter))

bind_rows(kpss,box, shap) %>%
  knitr::kable(
    format = "latex",
    align = c("lccc"),
    booktabs = TRUE,
    longtable = TRUE,
    linesep = "",
    escape = FALSE,
    digits = 2,
    col.names = c("", "Estatística", "p-valor", "Lag")
    ) %>%
  kableExtra::kable_styling(
      position = "center",
      latex_options = c("striped", "repeat_header"),
      stripe_color = "gray!15")

rm(box, shap, kpss)


```

## Modelo com transformação

### Seleção

```{r ets-lambda}
# avalia valor de lambda da transformacao boxcox
lambda <- dados %>% BoxCox.lambda()

dados_box <- dados %>% BoxCox(lambda)

```

Utilizando a função `BoxCox.lambda()` obtém-se uma sugestão de transformação com $\lambda =$ `r round(lambda,3)`. A série transformada é exibida no gráfico a seguir.

```{r ETS-com-transf}

# visualização e decomp da ETS com transformação
plot(dados_box,main= parse(text = paste0('"Série com transformação Box-Cox  "', '~ lambda == ', round(lambda, 3))))

```

No caso do modelo com transformação BoxCox a recomendação de modelo, obtida pelo mesmo método de varredura, é primariamente a seleção já feita para o modelo sem transformação, que é o $ETS(A, Ad, A)$.

```{r selecao-ETS-com-transformacao}
# for(i in 1:length(model$modelo)){
#   print(i)
#   print(try({ets(dados_box, model = model$modelo[i], damped = model$damp[i])}, silent = TRUE))
# }

# selecionados_transf <- c(1, 2, 5, 6, 14, 18, 19:24, 27:30, 32, 34, 36)

model_select_transf <- model[selecionados,]

tabela_modelos_ETS_transf <- map2_df(model_select_transf$modelo, model_select_transf$damp, criterios, dados_box) %>%
  arrange(AIC) %>%
  mutate(modelo = case_when(
    damped == TRUE ~ str_replace(sigla, ",A", ",Ad"),
    .default = sigla
  ))

tabela_modelos_ETS_transf %>%
  select("Modelo transformado"= modelo, AIC:BIC)%>%
  head(6) %>%
  knitr::kable(
    format = "latex",
    align = c("lccc"),
    booktabs = TRUE,
    longtable = TRUE,
    linesep = "",
    escape = FALSE,
    digits = 2
    ) %>%
  kableExtra::kable_styling(
      position = "center",
      latex_options = c("striped", "repeat_header"),
      stripe_color = "gray!15")
```

Os componentes do ajuste do modelo $ETS(A, Ad, A)$ são expostas a seguir e, como no caso anterior, a transformação não apresenta nenhuma mudança aparente no comportamento da série.

```{r decomposicao-ets-com-transformacao}

fit_ets_box <- ets(dados_box, model = "AAA", damped = TRUE)

plot(fit_ets_box)
```

### Resíduos

Assim como ocorre para a série não transformada, os resíduos parecem exibir comportamento aleatório em torno de zero, autocorrelações próximas a zero e distribuição próxima à normal, mas com caudas mais pesadas.

```{r resíduos-modelo-transformado, fig.height=5, fig.width = 7, fig.align='center'}

E4 <- fit_ets_box$residuals
par(mfrow=c(2,2))
plot(E4, main = "Resíduos")
acf(E4)
pacf(E4)
qqnorm(E4)
qqline(E4)

```

Novamente, os testes de hipótese expostos na tabela a seguir corroboram a hipótese de se tratar de uma série estacionária, com resíduos normalmente distribuídos e mutuamente independentes.

```{r residuos-ets-com-transformacao}
# # Testes para ETS com transformação
box <- Box.test(E4,lag=15,type="Ljung-Box") %>% tidy() %>% select(method, everything()) %>% mutate(parameter = as.character(parameter)) #independencia
shap <- shapiro.test(E4) %>% tidy() %>% mutate(parameter = "") %>% select(method, everything())  #normalidade
kpss <- kpss.test(E4) %>% tidy() %>% select(method, everything()) %>% mutate(parameter = as.character(parameter))

bind_rows(kpss,box, shap) %>%
  knitr::kable(
    format = "latex",
    align = c("lccc"),
    booktabs = TRUE,
    longtable = TRUE,
    linesep = "",
    escape = FALSE,
    digits = 2,
    col.names = c("", "Estatística", "p-valor", "Lag")
    ) %>%
  kableExtra::kable_styling(
      position = "center",
      latex_options = c("striped", "repeat_header"),
      stripe_color = "gray!15")

rm(box, shap, kpss)


```

# Estudo de desempenho preditivo

Para realizar a análise do desempenho preditivo usando uma abordagem de janela deslizante, o estudo considera uma janela de tamanho $n-14$ e calcula os erros de previsão para horizontes de até 5 períodos. Utilizando os modelos previamente mencionados para criar as funções de previsão, os resultados são apresentados em um gráfico e uma tabela, mostrando os erros absolutos para cada horizonte de previsão.

## Resultados da Janela Deslizante

```{r funcoes-previsao}
# Definindo as funções de previsão

# Arima
f_arima <- function(y, h){
fit = Arima(y, order=c(2,1,2), seasonal=c(0,1,2))
return(forecast(fit, h))
}

# Arima com transformação
f_arima_transf <- function(y, h){
fit = Arima(y, order=c(2,1,2), seasonal=c(0,1,2), lambda = 0.712)
forecast(fit, h)
}

# ETS
f_ets <- function(y, h){
fit = ets(y, model="AAA", damped = TRUE)
forecast(fit, h)
}

# ETS com transformação
f_ets_transf <- function(y, h){
fit = ets(y, model="AAA", lambda = 0.712, damped = TRUE)
forecast(fit, h)
}
```

```{r erros-previsao}
# Tamanho da série
n <- length(dados)

# Cálculo dos erros de previsão para cada método

CV_arima <- tsCV(y = dados, forecastfunction = f_arima, h = 5, initial = n-14)

CV_arima_transf <- tsCV(y = dados, forecastfunction = f_arima_transf,
                       h = 5, initial = n-14)

CV_ets <- tsCV(y = dados, forecastfunction = f_ets, h = 5, initial = n-14)

CV_ets_transf <- tsCV(y = dados, forecastfunction = f_ets_transf,
                     h = 5, initial = n-14)

# Cálculo do erro absoluto médio (MAE) para cada horizonte de previsão ----

#-------------- otimizado abaixo -------------#
# MAE_arima <- CV_arima %>% abs() %>% colMeans(na.rm=T)
# MAE_arima_transf <-  CV_arima_transf %>% abs() %>% colMeans(na.rm=T)
# MAE_ets <-  CV_ets %>% abs() %>% colMeans(na.rm=T)
# MAE_ets_transf <-  CV_ets_transf %>% abs() %>% colMeans(na.rm=T)
# 
# tab <- cbind(as.numeric(MAE_arima), as.numeric(MAE_ets))
# tab_transf <- cbind(MAE_arima_transf, MAE_ets_transf)
# 
# tab_erros <-  tibble(MAE_arima, MAE_ets, MAE_arima_transf, MAE_ets_transf)
#-------------------------------------------#

tab_erros <- tibble(
  h = paste0("h=", c(1:5)),
  MAE_arima = CV_arima %>% abs() %>% colMeans(na.rm=T),
  MAE_arima_transf =  CV_arima_transf %>% abs() %>% colMeans(na.rm=T),
  MAE_ets =  CV_ets %>% abs() %>% colMeans(na.rm=T),
  MAE_ets_transf =  CV_ets_transf %>% abs() %>% colMeans(na.rm=T),
)


tab_erros %>%
  knitr::kable(
    format = "latex",
    align = c("c"),
    booktabs = TRUE,
    longtable = TRUE,
    linesep = "",
    escape = FALSE,
    col.names = c('', 'ARIMA', 'ETS', 'ARIMA Transformada', 'ETS Transformada'),
    digits = 3
    ) %>%
  kableExtra::kable_styling(
      position = "center",
      latex_options = c("striped", "repeat_header"),
      stripe_color = "gray!15")
```

## Performance em relação aos horizontes de previsão

```{r performance, fig.height=3, fig.width = 4.5, fig.align='center'}
tab_erros %>%
  pivot_longer(cols = -h, names_to = "Modelo", values_to = "values")%>%
  mutate(
    Modelo = str_remove_all(Modelo, "MAE_"),
    h = str_remove_all(h, "h="),
    h = as.integer(h)) %>%
  ggplot(aes(h, values, color = Modelo))+
  geom_line()+
  labs(y = "MAE")+
  theme_bw()

# tab_erros %>%
#   select(-h) %>%
#   plot.ts(plot.type='s',col=1:4,lwd=2,xlab="h",ylab="MAE")
#   legend(x=1,y=0.44, legend=c("ARIMA", "ETS", "ARIMA Transformada", "ETS Transformada"), col=1:4, lwd=2)
```

Ao analisar o gráfico obtido, observa-se que o modelo ARIMA, tanto para a série original quanto para a série transformada, apresentou erros médios menores na maioria dos horizontes de previsão, com exceção do horizonte 1. Portanto, o modelo $\text{ARIMA}(2,1,2)\times(0,1,2)_{12}$ obteve melhor comportamento para o caso original e o caso transformado.

# Gráficos da previsão pontual e da previsão intervalar dos 4 modelos selecionados

Utilizou-se o modelo $\text{ARIMA}(2,1,2)\times(0,1,2)_{12}$ para realizar previsões pontuais e intervalares dos modelos selecionados. O horizonte de previsão fornecido pelo banco de dados foi de 18 pontos.

Os gráficos fornecidos permitem visualizar as previsões pontuais e intervalares da série temporal da competição de previsão M3, com uma probabilidade de cobertura de 95%. Já as tabelas, apresentam as previsões para um horizonte de 18 pontos e fornecem os intervalos das probabilidades de cobertura 80% e 95%.

Ao analisar os gráficos e as tabelas nas seções a seguir, observa-se que em todos eles a previsão está aparentemente ajustada à série original e os intervalos de probabilidades de cobertura analisados possuem aproximadamente o mesmo espectro.

{{< pagebreak >}}

## ARIMA

```{r previsao-pontual-arima, fig.align='center', fig.height=3}
# Verificando o h
h <- M3[[id]]$h

# Gráficos de previsão pontual e intervalar

# ARIMA
arima_prev95 <- f_arima(dados, h)

plot(arima_prev95, main = "Previsão 95% de probabilidade de cobertura")

linhas <- c("Sep 1992","Oct 1992","Nov 1992","Dec 1992","Jan 1993","Feb 1993","Mar 1993","Apr 1993","May 1993","Jun 1993","Jul 1993","Aug 1993","Sep 1993","Oct 1993","Nov 1993","Dec 1993","Jan 1994","Feb 1994")


arima_prev95 %>% 
  as_tibble() %>%
  mutate(t = linhas)%>%
  select(t, everything()) %>%
  knitr::kable(
      format = "latex",
      align = c("c"),
      booktabs = TRUE,
      longtable = TRUE,
      linesep = "",
      escape = FALSE,
      digits = 2,
      col.names = c("Período (mês/ano)", "Prev. Pontual", "LI", "LS", "LI", "LS")) %>%
    add_header_above(c(" " = 2, "IC para 80%" = 2, "IC para 95%" = 2))

```

{{< pagebreak >}}

## ARIMA com transformação

```{r previsao-pontual-arima-transf, fig.align='center', fig.height=3}
# ARIMA com transformação
arima_transf_prev95 <- f_arima_transf(dados, h)

plot(arima_transf_prev95, main = "Previsão 95% de probabilidade de cobertura")

arima_transf_prev95 %>% 
  as_tibble() %>%
  mutate(t = linhas)%>%
  select(t, everything()) %>%
  knitr::kable(
      format = "latex",
      align = c("c"),
      booktabs = TRUE,
      longtable = TRUE,
      linesep = "",
      escape = FALSE,
      digits = 2,
      col.names = c("Período (mês/ano)", "Prev. Pontual", "LI", "LS", "LI", "LS")) %>%
    add_header_above(c(" " = 2, "IC para 80%" = 2, "IC para 95%" = 2))
```

{{< pagebreak >}}

## ETS

```{r previsao-pontual-ets, fig.align='center', fig.height=3}
# ETS
ets_prev95 <- f_ets(dados, h)

plot(ets_prev95, main = "Previsão 95% de probabilidade de cobertura")

ets_prev95 %>% 
  as_tibble() %>%
  mutate(t = linhas)%>%
  select(t, everything()) %>%
  knitr::kable(
      format = "latex",
      align = c("c"),
      booktabs = TRUE,
      longtable = TRUE,
      linesep = "",
      escape = FALSE,
      digits = 2,
      col.names = c("Período (mês/ano)", "Prev. Pontual", "LI", "LS", "LI", "LS")) %>%
    add_header_above(c(" " = 2, "IC para 80%" = 2, "IC para 95%" = 2))
```

{{< pagebreak >}}

## ETS com transformação

```{r previsao-pontual-ets-transf, fig.align='center', fig.height=3}
# ETS com transformação
ets_transf_prev95 <- f_ets_transf(dados, h)

plot(ets_transf_prev95, main = "Previsão 95% de probabilidade de cobertura")

ets_transf_prev95 %>% 
  as_tibble() %>%
  mutate(t = linhas)%>%
  select(t, everything()) %>%
  knitr::kable(
      format = "latex",
      align = c("c"),
      booktabs = TRUE,
      longtable = TRUE,
      linesep = "",
      escape = FALSE,
      digits = 2,
      col.names = c("Período (mês/ano)", "Prev. Pontual", "LI", "LS", "LI", "LS")) %>%
    add_header_above(c(" " = 2, "IC para 80%" = 2, "IC para 95%" = 2))
```

{{< pagebreak >}}

# Resultados

Foi utilizada a métrica do erro absoluto médio (MAE) para comparar o desempenho preditivo dos modelos selecionados com alguns *benchmarks* da biblioteca *forecast*. Estes valores estão apresentados no gráfico abaixo e evidenciam uma melhor performance do modelo gerado pela função automática *auto.arima()*, seguido pelos modelos ARIMA selecionados manualmente.

```{r mae-benchmarks}
## MAE (Benchmarks)

n <- length(dados)

# auto.arima
f_auto_arima <- function(y, h){
  fit = auto.arima(y)
  forecast(fit, h)
}

CV_auto_arima <- tsCV(y=dados,forecastfunction=f_auto_arima,h=5,initial=n-14)

# ses
f_ses <- function(y, h){
  ses(y,h)
}
CV_ses <- tsCV(y=dados,forecastfunction=f_ses,h=5,initial=n-14)

# holt
f_holt <- function(y, h){
  holt(y,h)
}
CV_holt <- tsCV(y=dados,forecastfunction=f_holt,h=5,initial=n-14)

# ets
f_auto_ets <- function(y, h){
  fit = ets(y)
  forecast(fit, h)
}
CV_auto_ets <- tsCV(y=dados,forecastfunction=f_auto_ets,h=5,initial=n-14)

# stlf
f_stlf <- function(y, h){
  stlf(y,h)
}
CV_stlf <- tsCV(y=dados,forecastfunction=f_stlf,h=5,initial=n-14)

# bats
f_bats <- function(y, h){
  fit = bats(y)
  forecast(fit, h)
}
CV_bats <- tsCV(y=dados,forecastfunction=f_bats,h=5,initial=n-14)

# tbats
f_tbats <- function(y, h){
  fit = tbats(y)
  forecast(fit, h)
}
CV_tbats <- tsCV(y=dados,forecastfunction=f_tbats,h=5,initial=n-14)

# tabela
tabela <- tibble(
  h = paste0("h=", c(1:5)),
  MAE_arima = CV_arima %>% abs() %>% colMeans(na.rm=T),
  MAE_arima_transf =  CV_arima_transf %>% abs() %>% colMeans(na.rm=T),
  MAE_ets =  CV_ets %>% abs() %>% colMeans(na.rm=T),
  MAE_ets_transf =  CV_ets_transf %>% abs() %>% colMeans(na.rm=T),
  MAE_auto_arima = CV_auto_arima %>% abs() %>% colMeans(na.rm=T),
  MAE_ses = CV_ses %>% abs() %>% colMeans(na.rm=T),
  MAE_holt = CV_holt %>% abs() %>% colMeans(na.rm=T),
  MAE_auto_ets = CV_auto_ets %>% abs() %>% colMeans(na.rm=T),
  MAE_stlf = CV_stlf %>% abs() %>% colMeans(na.rm=T),
  MAE_bats = CV_bats %>% abs() %>% colMeans(na.rm=T),
  MAE_tbats = CV_tbats %>% abs() %>% colMeans(na.rm=T),
)

```

```{r mae-grafico, fig.height=3, fig.width = 4.5, fig.align='center'}
# MAE (grafico)
tabela %>%
  pivot_longer(cols = -h, names_to = "Modelo", values_to = "values")%>%
  mutate(
    Modelo = str_remove_all(Modelo, "MAE_"),
    h = str_remove_all(h, "h="),
    h = as.integer(h)) %>%
  ggplot(aes(h, values, color = Modelo))+
  geom_line()+
  labs(y = "MAE")+
  theme_bw()
```

# Conclusão

Neste estudo de caso, a performance dos modelos ARIMA é superior aos demais modelos selecionados manualmente em todos os horizontes de previsão. Ainda, como é possível observar no gráfico de comparação com os *benchmarks*, as funções do grupo arima parecem se comportar como um grupo separado com desempenho melhor que as demais, pelo menos até um horizonte de previsão $h=5$. Para esta série, portanto, indica-se um modelo ARIMA obtido pela função `auto.arima()`.

# Apêndice

Todo o projeto de composição deste documento pode ser encontrado aqui: <https://github.com/cesar-galvao/trabalhos_series_temporais>

```{r codigo, eval = FALSE, echo = TRUE}

if(!("pacman" %in% installed.packages())){install.packages("pacman")}

pacman::p_load(Mcomp, tidyverse, forecast, fpp2, xts, tseries, tidymodels, kableExtra)



data(M3) #carrega os dados
id <- 2183 #série temporal escolhida

serie <- M3[[id]]

dados <- serie$x

plot(serie, main = "Série Temporal M3-2183")



serie_ms <- forecast::msts(dados, seasonal.periods = c(12))

# media dos resíduos é em torno de 5. Considerando a magnitude dos dados que temos usando summary(dados), está próximo de zero o suficiente

#tentei períodos secundários, porém o melhor ajuste é com apenas um ciclo anual. Só é possível dois ciclos secundários completos para análise até quadrienal, mas até aí todos apresentam resíduos inadequados. 

decomp_mstl <- mstl(serie_ms, lambda = NULL, t.window = 9)

#ajustar com lambda = "auto" até agora não parece fazer qualquer diferença



decomp_mstl %>% autoplot(main = "Decomposição MSTL com período anual simples") + labs(x = "Ano") + theme_bw()


# diferenciacoes comuns
# ndiffs(serie_ms)

#diferenciacoes sazonais
# serie_ms %>% diff() %>% nsdiffs()

serie_ms_diff <- serie_ms %>% diff() %>% diff(lag = 12)

# Inicializacao dos resíduos
fit <- Arima(dados, order=c(2,1,2), seasonal=c(0,1,2)) #modelo selecionado em outro estágio da análise
E <- window(fit$residuals, start=c(1984,1))

kpss.test(E) %>% 
  tidy()%>%
  select(method, statistic, `p.value`) %>%
  knitr::kable(
    format = "latex",
    align = c("lccc"),
    booktabs = TRUE,
    longtable = TRUE,
    linesep = "",
    escape = FALSE,
    digits = 2,
    col.names = c("", "Estatística", "p-valor")
    ) %>%
  kableExtra::kable_styling(
      position = "center",
      latex_options = c("striped", "repeat_header"),
      stripe_color = "gray!15")


# Graficos de Autocorrelacao
par(mfrow=c(1,3))
plot(serie_ms_diff, main="Série com diferenças",ylab="")
acf(serie_ms_diff, lag=12*6, main="ACF")
pacf(serie_ms_diff, lag=12*6, main="PACF")

melhor_AICc <- Inf
for(p in 0:2){
  for(q in 0:2){
    for(P in 0:2){
      for(Q in 0:2){
        
        #cat("p =",p,", q =",q,", P =",P,", Q =",Q,"\n")
        
        tryCatch({fit <- Arima(serie_ms, order=c(p,1,q), seasonal=c(P,1,Q))}, error=function(e){cat("",conditionMessage(e), "\n")})
        
        if(fit$aicc <= melhor_AICc){
          melhor_AICc <- fit$aicc
          #cat("p =",p,", q =",q,", P =",P,", Q =",Q,", AICc =",fit$aicc,"\n")
          }
        
      }
    }
  }
}

#melhor_AICc

# teste com auto.arima para verificar
#auto.arima(serie_ms)


# Analise de residuos
par(mfrow=c(1,3))
plot(E, main="Resíduos",ylab="")
qqnorm(E)
qqline(E)
acf(E,lag.max=12*6,main="ACF")


#Testes
box <- Box.test(E,lag=15,type="Ljung-Box") %>% tidy() %>% select(method, everything()) %>% mutate(parameter = as.character(parameter)) #independencia
shap <- shapiro.test(E) %>% tidy() %>% mutate(parameter = "") %>% select(method, everything())  #normalidade

bind_rows(box, shap) %>%
  knitr::kable(
    format = "latex",
    align = c("lccc"),
    booktabs = TRUE,
    longtable = TRUE,
    linesep = "",
    escape = FALSE,
    digits = 2,
    col.names = c("", "Estatística", "p-valor", "Lag")
    ) %>%
  kableExtra::kable_styling(
      position = "center",
      latex_options = c("striped", "repeat_header"),
      stripe_color = "gray!15")

rm(box, shap)


# Transformacao de Box-Cox
autolambda <- BoxCox.lambda(dados)
dadosbc <- BoxCox(dados, lambda=autolambda)


par(mfrow=c(1,2))
plot(dados, main='Série original',ylab='')
plot(dadosbc, main='Série transformada',ylab='')


# Diferencas (BC)
# ndiffs(dadosbc)
# dadosbc %>% diff() %>% nsdiffs()

dadosbcdiff <- dadosbc %>% diff() %>% diff(lag = 12)

fit2 <- Arima(dadosbc, order=c(2,1,2), seasonal=c(0,1,2))# modelo ajustado em etapa posterior da análise

E2 <- window(fit2$residuals, start=c(1984,1))

kpss.test(E2) %>% 
  tidy()%>%
  select(method, statistic, `p.value`) %>%
  knitr::kable(
    format = "latex",
    align = c("lccc"),
    booktabs = TRUE,
    longtable = TRUE,
    linesep = "",
    escape = FALSE,
    digits = 2,
    col.names = c("", "Estatística", "p-valor")
    ) %>%
  kableExtra::kable_styling(
      position = "center",
      latex_options = c("striped", "repeat_header"),
      stripe_color = "gray!15")


# Graficos de Autocorrelacao (BC)
par(mfrow=c(1,3))
plot(dadosbcdiff, main="Série (boxcox) com dif.",ylab="")
acf(dadosbcdiff, lag=12*6, main="ACF")
pacf(dadosbcdiff, lag=12*6, main="PACF")


# Criterio de Akaike (BC)
melhor_AICc <- Inf
for(p in 0:2){
  for(q in 0:2){
    for(P in 0:2){
      for(Q in 0:2){
        #cat("p =",p,", q =",q,", P =",P,", Q =",Q,"\n")
        tryCatch({fit <- Arima(dadosbc, order=c(p,1,q), seasonal=c(P,1,Q))}, error=function(e){cat("ERROR :",conditionMessage(e), "\n")})
        if(fit$aicc <= melhor_AICc){
          melhor_AICc <- fit$aicc
          #cat("p =",p,", q =",q,", P =",P,", Q =",Q,", AICc =",fit$aicc,"\n")}
        
      }
    }
  }
  }
}
# melhor_AICc

# auto.arima(serie_ms)


# Inicializacao
# Analise de residuos
par(mfrow=c(1,3))
plot(E2, main="Resíduos (boxcox)",ylab="")
qqnorm(E2)
qqline(E2)
acf(E,lag.max=12*6,main="ACF")


#Testes
box <- Box.test(E2,lag=15,type="Ljung-Box") %>% tidy() %>% select(method, everything()) %>% mutate(parameter = as.character(parameter)) #independencia
shap <- shapiro.test(E2) %>% tidy() %>% mutate(parameter = "") %>% select(method, everything())  #normalidade

bind_rows(box, shap) %>%
  knitr::kable(
    format = "latex",
    align = c("lccc"),
    booktabs = TRUE,
    longtable = TRUE,
    linesep = "",
    escape = FALSE,
    digits = 2,
    col.names = c("", "Estatística", "p-valor", "Lag")
    ) %>%
  kableExtra::kable_styling(
      position = "center",
      latex_options = c("striped", "repeat_header"),
      stripe_color = "gray!15")

rm(box, shap)


# monta as combinações possíveis de modelo ets
model <- expand_grid(v1 = c("A", "M", "N"), v2 = c("A", "M", "N"), v3 = c("A", "M", "N")) %>%
  mutate(modelo = str_c(v1,v2,v3)) %>%
  select(modelo) %>%
  unique() %>%
  expand_grid(., damp = c(TRUE, FALSE))
# N, A, M, + damped


#funcao pra montar indicadores do modelo
criterios <- function(modelo, damp, dados) { 
  ETS <- ets(dados, model = modelo, damped = damp)
  #usamos o objeto dados como um padrao
  
  tabela <- tibble(
    nome = modelo,
    sigla = str_c("ETS(", str_c(substr(modelo,1,1),  substr(modelo,2,2), substr(modelo,3,3), sep = ","), ")"),
    damped = damp,
    AIC = ETS$aic, 
    AICc = ETS$aicc, 
    BIC = ETS$bic)
  
  return(tabela)
}


#selecionando modelos permitidos pela funcao ets
# for(i in 1:length(model$modelo)){
#   print(i)
#   print(try({ets(dados, model = model$modelo[i], damped = model$damp[i])}, silent = TRUE))
# }

selecionados <- c(1, 2, 5, 6, 14, 18:24, 27:30, 32, 34, 36)

model_select <- model[selecionados,]

tabela_modelos_ETS <- map2_df(model_select$modelo, model_select$damp, criterios, dados) %>%
  arrange(AIC) %>%
  mutate(modelo = case_when(
    damped == TRUE ~ str_replace(sigla, ",A", ",Ad"),
    .default = sigla
  ))

tabela_modelos_ETS %>%
  select("Modelo"= modelo, AIC:BIC)%>%
  head(6) %>%
  knitr::kable(
    format = "latex",
    align = c("lccc"),
    booktabs = TRUE,
    longtable = TRUE,
    linesep = "",
    escape = FALSE,
    digits = 2
    ) %>%
  kableExtra::kable_styling(
      position = "center",
      latex_options = c("striped", "repeat_header"),
      stripe_color = "gray!15")



# decomposicao ETS sem transformacao ----
fit_ets <- ets(dados, model = "AAA", damped = TRUE)

plot(fit_ets)


# Análise de resíduos ETS sem transformação
E3 <- fit_ets$residuals
par(mfrow=c(2,2))
plot(E3, main = "Resíduos")
acf(E3)
pacf(E3)
qqnorm(E3)
qqline(E3)


# # Testes para ETS sem transformação
box <- Box.test(E3,lag=15,type="Ljung-Box") %>% tidy() %>% select(method, everything()) %>% mutate(parameter = as.character(parameter)) #independencia
shap <- shapiro.test(E3) %>% tidy() %>% mutate(parameter = "") %>% select(method, everything())  #normalidade
kpss <- kpss.test(E3) %>% tidy() %>% select(method, everything()) %>% mutate(parameter = as.character(parameter))

bind_rows(kpss,box, shap) %>%
  knitr::kable(
    format = "latex",
    align = c("lccc"),
    booktabs = TRUE,
    longtable = TRUE,
    linesep = "",
    escape = FALSE,
    digits = 2,
    col.names = c("", "Estatística", "p-valor", "Lag")
    ) %>%
  kableExtra::kable_styling(
      position = "center",
      latex_options = c("striped", "repeat_header"),
      stripe_color = "gray!15")

rm(box, shap, kpss)


# avalia valor de lambda da transformacao boxcox
lambda <- dados %>% BoxCox.lambda()

dados_box <- dados %>% BoxCox(lambda)


# visualização e decomp da ETS com transformação
plot(dados_box,main= parse(text = paste0('"Série com transformação Box-Cox  "', '~ lambda == ', round(lambda, 3))))


# for(i in 1:length(model$modelo)){
#   print(i)
#   print(try({ets(dados_box, model = model$modelo[i], damped = model$damp[i])}, silent = TRUE))
# }

# selecionados_transf <- c(1, 2, 5, 6, 14, 18, 19:24, 27:30, 32, 34, 36)

model_select_transf <- model[selecionados,]

tabela_modelos_ETS_transf <- map2_df(model_select_transf$modelo, model_select_transf$damp, criterios, dados_box) %>%
  arrange(AIC) %>%
  mutate(modelo = case_when(
    damped == TRUE ~ str_replace(sigla, ",A", ",Ad"),
    .default = sigla
  ))

tabela_modelos_ETS_transf %>%
  select("Modelo transformado"= modelo, AIC:BIC)%>%
  head(6) %>%
  knitr::kable(
    format = "latex",
    align = c("lccc"),
    booktabs = TRUE,
    longtable = TRUE,
    linesep = "",
    escape = FALSE,
    digits = 2
    ) %>%
  kableExtra::kable_styling(
      position = "center",
      latex_options = c("striped", "repeat_header"),
      stripe_color = "gray!15")


fit_ets_box <- ets(dados_box, model = "AAA", damped = TRUE)

plot(fit_ets_box)


E4 <- fit_ets_box$residuals
par(mfrow=c(2,2))
plot(E4, main = "Resíduos")
acf(E4)
pacf(E4)
qqnorm(E4)
qqline(E4)


# # Testes para ETS com transformação
box <- Box.test(E4,lag=15,type="Ljung-Box") %>% tidy() %>% select(method, everything()) %>% mutate(parameter = as.character(parameter)) #independencia
shap <- shapiro.test(E4) %>% tidy() %>% mutate(parameter = "") %>% select(method, everything())  #normalidade
kpss <- kpss.test(E4) %>% tidy() %>% select(method, everything()) %>% mutate(parameter = as.character(parameter))

bind_rows(kpss,box, shap) %>%
  knitr::kable(
    format = "latex",
    align = c("lccc"),
    booktabs = TRUE,
    longtable = TRUE,
    linesep = "",
    escape = FALSE,
    digits = 2,
    col.names = c("", "Estatística", "p-valor", "Lag")
    ) %>%
  kableExtra::kable_styling(
      position = "center",
      latex_options = c("striped", "repeat_header"),
      stripe_color = "gray!15")

rm(box, shap, kpss)


# Definindo as funções de previsão

# Arima
f_arima <- function(y, h){
fit = Arima(y, order=c(2,1,2), seasonal=c(0,1,2))
return(forecast(fit, h))
}

# Arima com transformação
f_arima_transf <- function(y, h){
fit = Arima(y, order=c(2,1,2), seasonal=c(0,1,2), lambda = 0.712)
forecast(fit, h)
}

# ETS
f_ets <- function(y, h){
fit = ets(y, model="AAA", damped = TRUE)
forecast(fit, h)
}

# ETS com transformação
f_ets_transf <- function(y, h){
fit = ets(y, model="AAA", lambda = 0.712, damped = TRUE)
forecast(fit, h)
}


# Tamanho da série
n <- length(dados)

# Cálculo dos erros de previsão para cada método

CV_arima <- tsCV(y = dados, forecastfunction = f_arima, h = 5, initial = n-14)

CV_arima_transf <- tsCV(y = dados, forecastfunction = f_arima_transf,
                       h = 5, initial = n-14)

CV_ets <- tsCV(y = dados, forecastfunction = f_ets, h = 5, initial = n-14)

CV_ets_transf <- tsCV(y = dados, forecastfunction = f_ets_transf,
                     h = 5, initial = n-14)

# Cálculo do erro absoluto médio (MAE) para cada horizonte de previsão ----

#-------------- otimizado abaixo -------------#
# MAE_arima <- CV_arima %>% abs() %>% colMeans(na.rm=T)
# MAE_arima_transf <-  CV_arima_transf %>% abs() %>% colMeans(na.rm=T)
# MAE_ets <-  CV_ets %>% abs() %>% colMeans(na.rm=T)
# MAE_ets_transf <-  CV_ets_transf %>% abs() %>% colMeans(na.rm=T)
# 
# tab <- cbind(as.numeric(MAE_arima), as.numeric(MAE_ets))
# tab_transf <- cbind(MAE_arima_transf, MAE_ets_transf)
# 
# tab_erros <-  tibble(MAE_arima, MAE_ets, MAE_arima_transf, MAE_ets_transf)
#-------------------------------------------#

tab_erros <- tibble(
  h = paste0("h=", c(1:5)),
  MAE_arima = CV_arima %>% abs() %>% colMeans(na.rm=T),
  MAE_arima_transf =  CV_arima_transf %>% abs() %>% colMeans(na.rm=T),
  MAE_ets =  CV_ets %>% abs() %>% colMeans(na.rm=T),
  MAE_ets_transf =  CV_ets_transf %>% abs() %>% colMeans(na.rm=T),
)


tab_erros %>%
  knitr::kable(
    format = "latex",
    align = c("c"),
    booktabs = TRUE,
    longtable = TRUE,
    linesep = "",
    escape = FALSE,
    col.names = c('', 'ARIMA', 'ETS', 'ARIMA Transformada', 'ETS Transformada'),
    digits = 3
    ) %>%
  kableExtra::kable_styling(
      position = "center",
      latex_options = c("striped", "repeat_header"),
      stripe_color = "gray!15")


tab_erros %>%
  pivot_longer(cols = -h, names_to = "Modelo", values_to = "values")%>%
  mutate(
    Modelo = str_remove_all(Modelo, "MAE_"),
    h = str_remove_all(h, "h="),
    h = as.integer(h)) %>%
  ggplot(aes(h, values, color = Modelo))+
  geom_line()+
  labs(y = "MAE")+
  theme_bw()


# Verificando o h
h <- M3[[id]]$h

# Gráficos de previsão pontual e intervalar

# ARIMA
arima_prev95 <- f_arima(dados, h)

plot(arima_prev95, main = "Previsão 95% de probabilidade de cobertura")

linhas <- c("Sep 1992","Oct 1992","Nov 1992","Dec 1992","Jan 1993","Feb 1993","Mar 1993","Apr 1993","May 1993","Jun 1993","Jul 1993","Aug 1993","Sep 1993","Oct 1993","Nov 1993","Dec 1993","Jan 1994","Feb 1994")


arima_prev95 %>% 
  as_tibble() %>%
  mutate(t = linhas)%>%
  select(t, everything()) %>%
  knitr::kable(
      format = "latex",
      align = c("c"),
      booktabs = TRUE,
      longtable = TRUE,
      linesep = "",
      escape = FALSE,
      digits = 2,
      col.names = c("Período (mês/ano)", "Prev. Pontual", "LI", "LS", "LI", "LS")) %>%
    add_header_above(c(" " = 2, "IC para 80%" = 2, "IC para 95%" = 2))


# ARIMA com transformação
arima_transf_prev95 <- f_arima_transf(dados, h)

plot(arima_transf_prev95, main = "Previsão 95% de probabilidade de cobertura")

arima_transf_prev95 %>% 
  as_tibble() %>%
  mutate(t = linhas)%>%
  select(t, everything()) %>%
  knitr::kable(
      format = "latex",
      align = c("c"),
      booktabs = TRUE,
      longtable = TRUE,
      linesep = "",
      escape = FALSE,
      digits = 2,
      col.names = c("Período (mês/ano)", "Prev. Pontual", "LI", "LS", "LI", "LS")) %>%
    add_header_above(c(" " = 2, "IC para 80%" = 2, "IC para 95%" = 2))


# ETS
ets_prev95 <- f_ets(dados, h)

plot(ets_prev95, main = "Previsão 95% de probabilidade de cobertura")

ets_prev95 %>% 
  as_tibble() %>%
  mutate(t = linhas)%>%
  select(t, everything()) %>%
  knitr::kable(
      format = "latex",
      align = c("c"),
      booktabs = TRUE,
      longtable = TRUE,
      linesep = "",
      escape = FALSE,
      digits = 2,
      col.names = c("Período (mês/ano)", "Prev. Pontual", "LI", "LS", "LI", "LS")) %>%
    add_header_above(c(" " = 2, "IC para 80%" = 2, "IC para 95%" = 2))


# ETS com transformação
ets_transf_prev95 <- f_ets_transf(dados, h)

plot(ets_transf_prev95, main = "Previsão 95% de probabilidade de cobertura")

ets_transf_prev95 %>% 
  as_tibble() %>%
  mutate(t = linhas)%>%
  select(t, everything()) %>%
  knitr::kable(
      format = "latex",
      align = c("c"),
      booktabs = TRUE,
      longtable = TRUE,
      linesep = "",
      escape = FALSE,
      digits = 2,
      col.names = c("Período (mês/ano)", "Prev. Pontual", "LI", "LS", "LI", "LS")) %>%
    add_header_above(c(" " = 2, "IC para 80%" = 2, "IC para 95%" = 2))

## MAE (Benchmarks)

n <- length(dados)

# auto.arima
f_auto_arima <- function(y, h){
  fit = auto.arima(y)
  forecast(fit, h)
}

CV_auto_arima <- tsCV(y=dados,forecastfunction=f_auto_arima,h=5,initial=n-14)

# ses
f_ses <- function(y, h){
  ses(y,h)
}
CV_ses <- tsCV(y=dados,forecastfunction=f_ses,h=5,initial=n-14)

# holt
f_holt <- function(y, h){
  holt(y,h)
}
CV_holt <- tsCV(y=dados,forecastfunction=f_holt,h=5,initial=n-14)

# ets
f_auto_ets <- function(y, h){
  fit = ets(y)
  forecast(fit, h)
}
CV_auto_ets <- tsCV(y=dados,forecastfunction=f_auto_ets,h=5,initial=n-14)

# stlf
f_stlf <- function(y, h){
  stlf(y,h)
}
CV_stlf <- tsCV(y=dados,forecastfunction=f_stlf,h=5,initial=n-14)

# bats
f_bats <- function(y, h){
  fit = bats(y)
  forecast(fit, h)
}
CV_bats <- tsCV(y=dados,forecastfunction=f_bats,h=5,initial=n-14)

# tbats
f_tbats <- function(y, h){
  fit = tbats(y)
  forecast(fit, h)
}
CV_tbats <- tsCV(y=dados,forecastfunction=f_tbats,h=5,initial=n-14)

# tabela
tabela <- tibble(
  h = paste0("h=", c(1:5)),
  MAE_arima = CV_arima %>% abs() %>% colMeans(na.rm=T),
  MAE_arima_transf =  CV_arima_transf %>% abs() %>% colMeans(na.rm=T),
  MAE_ets =  CV_ets %>% abs() %>% colMeans(na.rm=T),
  MAE_ets_transf =  CV_ets_transf %>% abs() %>% colMeans(na.rm=T),
  MAE_auto_arima = CV_auto_arima %>% abs() %>% colMeans(na.rm=T),
  MAE_ses = CV_ses %>% abs() %>% colMeans(na.rm=T),
  MAE_holt = CV_holt %>% abs() %>% colMeans(na.rm=T),
  MAE_auto_ets = CV_auto_ets %>% abs() %>% colMeans(na.rm=T),
  MAE_stlf = CV_stlf %>% abs() %>% colMeans(na.rm=T),
  MAE_bats = CV_bats %>% abs() %>% colMeans(na.rm=T),
  MAE_tbats = CV_tbats %>% abs() %>% colMeans(na.rm=T),
)

# MAE (grafico)
tabela %>%
  pivot_longer(cols = -h, names_to = "Modelo", values_to = "values")%>%
  mutate(
    Modelo = str_remove_all(Modelo, "MAE_"),
    h = str_remove_all(h, "h="),
    h = as.integer(h)) %>%
  ggplot(aes(h, values, color = Modelo))+
  geom_line()+
  labs(y = "MAE")+
  theme_bw()

```

```{r include = FALSE}
rm(list = ls())
gc()

```
